# -*- coding: utf-8 -*-
"""ML - Recommandation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pEZJ4fUuqUu1gFHwGGvQ_ENsCrccm7Y6
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.neighbors import NearestNeighbors
import joblib
from fonction_ml import (
    weight_text,
    weight_names,
    weight_year,
    weight_numbers
)

# récupération dataframe
df = pd.read_csv("db/data_2.csv")

# Colonnes qu'on veut retenir :
# StartYear - genres - averageRating - nomVotes - production_companies_name - writers - directors - actors - key words

# transformation en liste des colonnes qu'on veut concaténer dans "full_text"

df["genres"] = df["genres"].apply(eval)
df["production_companies_name"] = df["production_companies_name"].apply(eval)
df["key_words"] = df["key_words"].apply(eval)

# fonction de concaténation

def concatener(df):
  liste =[]

  genre = df['genres']
  prod = df['production_companies_name']
  key = df['key_words']

  for i in genre:
    liste.append(i)
  for i in prod:
    liste.append(i)
  for i in key:
    liste.append(i)

  return liste

# on rassemble les infos textuelles dans une seule colonnes avec la fonction concaténer

df["full_text"] = df.apply(concatener, axis = 1)

# Définition de nos features sur lesquels on va entrainer le ML

X = df[["full_text","startYear","averageRating","numVotes","writers","directors","actors"]]

# transformation des colonnes "listes" en vraie listes

X["writers"] = X["writers"].apply(eval)
X["directors"] = X["directors"].apply(eval)
X["actors"] = X["actors"].apply(eval)

# fonction suppression espace entre prénom et nom + transformation en string

def supr_espace(liste):
  string = ""
  for i in liste:
    string = string + " " +  i.replace(" ","")
  return string

# fonction transformation en string

def stringify(liste):
  string = ""
  for i in liste:
    string = string + " " +  i
  return string

# application des fonctions stringify et supr_espace aux features

X["writers"] = X["writers"].apply(supr_espace)
X["actors"] = X["actors"].apply(supr_espace)
X["directors"] = X["directors"].apply(supr_espace)
X["full_text"] = df["full_text"].apply(stringify)

# on peut ajuster le poids de chaque feature

from sklearn.preprocessing import FunctionTransformer     # rend utilisable n'importe quelle fonction dans un pipeline

# Créer un transformateur personnalisé pour pondérer les features




preprocessor = ColumnTransformer(
    transformers=[
        ("text", Pipeline([
            ("tfidf", TfidfVectorizer(max_features = 2000, ngram_range = (1,2))),
            ("weight", FunctionTransformer(weight_text))
        ]), "full_text"),

        ("names", Pipeline([
            ("ohe", OneHotEncoder(handle_unknown="ignore", max_categories=1500)),
            ("weight", FunctionTransformer(weight_names))
        ]), ["actors","directors","writers"]),

        ("Number", Pipeline([
            ("scaler", StandardScaler()),
            ("weight", FunctionTransformer(weight_year))
        ]), ['startYear']),

        ("Numbers", Pipeline([
            ("scaler", StandardScaler()),
            ("weight", FunctionTransformer(weight_numbers))
        ]), ['averageRating',"numVotes"])
    ]
)

pipeline = Pipeline([
    ("prep", preprocessor),
    ("nn", NearestNeighbors(metric="cosine", n_neighbors=7))
])


# On entraine notre ML sur nos features (X)

pipeline.fit(X)

# On teste notre ML sur le film indice 10
distances, indices = pipeline.named_steps["nn"].kneighbors(
    pipeline.named_steps["prep"].transform(X.iloc[[10]])
)

# on récupère la liste des indices (7 dont le film lui-même)
indexes  = indices[0]

joblib.dump(pipeline,'model_recommandation')